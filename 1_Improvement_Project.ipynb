{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b658e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(r\"C:\\Users\\E1460340\\Desktop\\New\")\n",
    "\n",
    "# Function to detect encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "# Read datasets\n",
    "dataframes = {}\n",
    "\n",
    "for file in folder_path.iterdir():\n",
    "    if \"Dataset\" in file.name:\n",
    "        for dataset in file.iterdir():\n",
    "            if \"Actual\" in dataset.name:\n",
    "                for actual_file in dataset.iterdir():\n",
    "                    if \"Firm and Forecast Orders\" in actual_file.name:\n",
    "                        dataframes['actual_orders'] = pd.read_csv(actual_file, low_memory=False)\n",
    "                    elif \"Shipment\" in actual_file.name:\n",
    "                        dataframes['actual_shipments'] = pd.read_csv(actual_file, low_memory=False)\n",
    "            \n",
    "            elif \"Prior\" in dataset.name:\n",
    "                for prior_file in dataset.iterdir():\n",
    "                    if \"Firm and Forecast Orders\" in prior_file.name:\n",
    "                        dataframes['prior_orders'] = pd.read_csv(prior_file, low_memory=False)\n",
    "                    elif \"Shipment\" in prior_file.name:\n",
    "                        dataframes['prior_shipments'] = pd.read_csv(prior_file, low_memory=False)\n",
    "\n",
    "            elif \"Demantra\" in dataset.name:\n",
    "                for demantra_file in dataset.iterdir():\n",
    "                    if \"Demantra\" in demantra_file.name:\n",
    "                        encoding = detect_encoding(demantra_file)\n",
    "                        dataframes['demand_plan'] = pd.read_csv(demantra_file, delimiter=\"\\t\", encoding=encoding, low_memory=False)\n",
    "\n",
    "            elif \"factAdjustments\" in dataset.name:\n",
    "                dataframes['adjustments'] = pd.read_excel(dataset, sheet_name=\"Adjustments\")\n",
    "\n",
    "    elif \"Lookup\" in file.name:\n",
    "        for lookup_file in file.iterdir():\n",
    "            excel_file = pd.ExcelFile(lookup_file)\n",
    "            tab_list = excel_file.sheet_names\n",
    "            for tab in tab_list:\n",
    "                dataframes[tab] = pd.read_excel(lookup_file, sheet_name= tab)\n",
    "\n",
    "# Rename columns\n",
    "rename_dict = {\n",
    "    'SCHEDULE_SHIP_DATE': 'SHIP_DATE',\n",
    "    'ORDERED_QUANTITY': 'SHIPPED_QUANTITY',\n",
    "    'Site Cust': 'LEGACY_ACCOUNT_NUMBER',\n",
    "    'Application Code': 'APPLICATION_CODE',\n",
    "    'Time': 'SHIP_MONTH',\n",
    "    'Fiscal Week / Series': 'SHIP_WEEK',\n",
    "    'DP Plan Proj': 'DP_PLAN'\n",
    "}\n",
    "\n",
    "for key in ['actual_orders', 'prior_orders']:\n",
    "    dataframes[key].rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Merge dataframes\n",
    "res_actual = pd.concat([dataframes['actual_shipments'], dataframes['actual_orders']], ignore_index=True)\n",
    "res_prior = pd.concat([dataframes['prior_shipments'], dataframes['prior_orders']], ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "res_actual.rename(columns={'SHIPPED_QUANTITY': 'ACTUAL'}, inplace=True)\n",
    "res_prior.rename(columns={'SHIPPED_QUANTITY': 'PRIOR'}, inplace=True)\n",
    "\n",
    "# Combine datasets\n",
    "res_data = pd.concat([res_actual, res_prior], ignore_index=True)\n",
    "\n",
    "# Apply filtering\n",
    "res_data = res_data[(res_data['CUSTOMER_TYPE'] == 'External') & (res_data['PORBU'] == 'AC_PORBU')]\n",
    "\n",
    "# Merge lookup tables\n",
    "res_data = res_data.merge(dataframes['LOOKUP_RES_PLATFORM'], how='inner', on='PLATFORM')\n",
    "res_data = res_data.merge(dataframes['LOOKUP_RES_APPCODE'], how='left', left_on='APPLICATION_CODE', right_on='APP_CODE').rename(columns={'SEGMENT_y': 'SEGMENT'})\n",
    "\n",
    "# Fill missing SEGMENT valuesL\n",
    "res_data['SEGMENT'] = res_data['SEGMENT'].fillna('OTHERS')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "res_df = res_data[['SHIP_DATE', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER', 'PLATFORM', 'ACTUAL', 'PRIOR']].copy()\n",
    "\n",
    "# Convert SHIP_DATE to datetime and format properly\n",
    "res_df['SHIP_DATE'] = pd.to_datetime(res_df['SHIP_DATE'], format='mixed').dt.strftime(\"%m/%d/%Y\")\n",
    "res_df['SHIP_MONTH'] = pd.to_datetime(res_df['SHIP_DATE']).dt.strftime('%m/1/%Y')\n",
    "res_df['SHIP_WEEK'] = pd.to_datetime(res_df['SHIP_DATE']).dt.to_period('W').dt.start_time.dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "# Group data to reduce row count\n",
    "res_df = res_df.groupby(['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(ACTUAL=('ACTUAL', 'sum'), PRIOR=('PRIOR', 'sum')).reset_index()\n",
    "\n",
    "# Merge adjustments\n",
    "adjustments = dataframes['adjustments'].copy()\n",
    "adjustments['SEGMENT'] = 'RESIDENTIAL'\n",
    "adjustments['SHIP_MONTH'] = pd.to_datetime(adjustments['SHIP_DATE'], format='%d-%b-%y').dt.strftime('%m/%d/%Y')\n",
    "adjustments[['ACTUAL', 'PRIOR']] = adjustments[['ACTUAL', 'PRIOR']].fillna(0)\n",
    "\n",
    "res_adj = adjustments.groupby(['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(adjustments_ACTUAL=('ACTUAL', 'sum'), adjustments_PRIOR=('PRIOR', 'sum')).reset_index()\n",
    "\n",
    "df_adj = res_df.merge(res_adj, how='left', on=['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).fillna(0)\n",
    "df_adj['ACTUAL'] = df_adj['ACTUAL'] + df_adj['adjustments_ACTUAL']\n",
    "df_adj['PRIOR'] = df_adj['PRIOR'] + df_adj['adjustments_PRIOR']\n",
    "\n",
    "# Final dataset\n",
    "data_complete = df_adj[['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER', 'ACTUAL', 'PRIOR']]\n",
    "data_complete.to_csv(folder_path / 'clean_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
