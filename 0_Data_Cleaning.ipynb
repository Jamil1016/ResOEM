{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05385f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show the best guess for the encoding\n",
    "# import chardet\n",
    "\n",
    "# with open(r\"C:\\Users\\E1460340\\Desktop\\New\\Dataset\\Demantra\\Demantra.txt\", \"rb\") as f:\n",
    "#     result = chardet.detect(f.read())\n",
    "#     print(result) \n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(r\"C:\\Users\\E1460340\\Desktop\\New\")\n",
    "\n",
    "for file in folder_path.iterdir():\n",
    "    if file.name.__contains__(\"Dataset\"):\n",
    "        for dataset in file.iterdir():\n",
    "            # Dataframe for Actual\n",
    "            if dataset.name.__contains__(\"Actual\"):\n",
    "                for actual_file in dataset.iterdir():\n",
    "                    if actual_file.name.__contains__(\"Firm and Forecast Orders\"):\n",
    "                        data_actual_orders = pd.read_csv(actual_file, low_memory= False)\n",
    "                    elif actual_file.name.__contains__(\"Shipment\"):\n",
    "                        data_actual_shipments = pd.read_csv(actual_file, low_memory= False)\n",
    "                    else:\n",
    "                        pass\n",
    "            # Dataframe for Prior\n",
    "            elif dataset.name.__contains__(\"Prior\"):\n",
    "                for actual_file in dataset.iterdir():\n",
    "                    if actual_file.name.__contains__(\"Firm and Forecast Orders\"):\n",
    "                        data_prior_orders = pd.read_csv(actual_file, low_memory= False)\n",
    "                    elif actual_file.name.__contains__(\"Shipment\"):\n",
    "                        data_prior_shipments = pd.read_csv(actual_file, low_memory= False)\n",
    "                    else:\n",
    "                        pass\n",
    "            # Dataframe for Demand Plan\n",
    "            elif dataset.name.__contains__(\"Demantra\"):\n",
    "                for file in dataset.iterdir():\n",
    "                    if \"Demantra\" in file.name:\n",
    "                        data_demand_plan = pd.read_csv(file, delimiter= \"\\t\", encoding= \"UTF-16\", low_memory= False)\n",
    "                    else:\n",
    "                        pass\n",
    "            # Dataframe for Adjustments\n",
    "            elif dataset.name.__contains__(\"factAdjustments\"):\n",
    "                adjustments = pd.read_excel(dataset, sheet_name= \"Adjustments\")\n",
    "            else:\n",
    "                pass\n",
    "    elif file.name.__contains__(\"Lookup\"):\n",
    "        for lookup in file.iterdir():\n",
    "            lookup_ResOEM = pd.read_excel(lookup, sheet_name= \"LOOKUP_RES_OEM\")\n",
    "            lookup_ResAppCode = pd.read_excel(lookup, sheet_name= \"LOOKUP_RES_APPCODE\")\n",
    "            lookup_ResPlatform = pd.read_excel(lookup, sheet_name= \"LOOKUP_RES_PLATFORM\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# For making Res OEM Report merging actual and prior data\n",
    "data_actual_orders.rename(columns={'SCHEDULE_SHIP_DATE':'SHIP_DATE','ORDERED_QUANTITY':'SHIPPED_QUANTITY'}, inplace= True)\n",
    "data_prior_orders.rename(columns={'SCHEDULE_SHIP_DATE':'SHIP_DATE','ORDERED_QUANTITY':'SHIPPED_QUANTITY'}, inplace= True)\n",
    "\n",
    "Res_actual = pd.concat([data_actual_shipments,data_actual_orders],ignore_index= True)\n",
    "Res_prior = pd.concat([data_prior_shipments,data_prior_orders], ignore_index= True)\n",
    "\n",
    "Res_actual.rename(columns={'SHIPPED_QUANTITY':'ACTUAL'}, inplace= True)\n",
    "Res_prior.rename(columns={'SHIPPED_QUANTITY':'PRIOR'}, inplace= True)\n",
    "\n",
    "Res_data = pd.concat([Res_actual,Res_prior], ignore_index= True)\n",
    "\n",
    "# Filtering data\n",
    "Res_data = Res_data[(Res_data['CUSTOMER_TYPE'] == 'External') & (Res_data['PORBU'] == 'AC_PORBU')]\n",
    "Res_data = Res_data.merge(lookup_ResPlatform, how= 'inner', on= 'PLATFORM')\n",
    "\n",
    "# Adding column for SEGMENT\n",
    "Res_data = Res_data.merge(lookup_ResAppCode, how= 'left', left_on= 'APPLICATION_CODE', right_on= 'APP_CODE').rename(columns={'SEGMENT_y':'SEGMENT'})\n",
    "Res_data['SEGMENT'] = Res_data['SEGMENT'].fillna('OTHERS')\n",
    "\n",
    "# Removing other columns\n",
    "Res_df = Res_data[['SHIP_DATE', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER', 'PLATFORM', 'ACTUAL', 'PRIOR']].copy()\n",
    "\n",
    "# Making columns for SHIP_MONTH and SHIP_WEEK (start of week ;'monday')\n",
    "Res_df['SHIP_DATE'] = pd.to_datetime(Res_df['SHIP_DATE'], format= 'mixed').dt.strftime(\"%m/%d/%Y\")\n",
    "Res_df['SHIP_MONTH'] = pd.to_datetime(Res_df['SHIP_DATE']).dt.strftime('%m/1/%Y')\n",
    "Res_df['SHIP_WEEK'] = pd.to_datetime(Res_df['SHIP_DATE']).dt.to_period('W').dt.start_time.dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "# grouping the data for ['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER'] to reduce the row count.\n",
    "Res_df = Res_df.groupby(['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(ACTUAL= ('ACTUAL','sum'), PRIOR= ('PRIOR','sum')).reset_index()\n",
    "\n",
    "\n",
    "# Working with the adjustments\n",
    "    # Adding percentage of weekly value to monthly\n",
    "total_monthly = Res_df.groupby(['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(monthly_ACTUAL= ('ACTUAL','sum'), monthly_PRIOR= ('PRIOR','sum')).reset_index()\n",
    "Res_df = Res_df.merge(total_monthly, how= 'left' ,on= ['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER'])\n",
    "Res_df['%_ACTUAL'] = Res_df['ACTUAL'].div(Res_df['monthly_ACTUAL']).fillna(0)\n",
    "Res_df['%_PRIOR'] = Res_df['PRIOR'].div(Res_df['monthly_PRIOR']).fillna(0)\n",
    "\n",
    "    # Cleaning the adjustments to align for Res data\n",
    "adjustments['SEGMENT'] = 'RESIDENTIAL'\n",
    "adjustments['SHIP_MONTH'] = pd.to_datetime(adjustments['SHIP_DATE'], format= 'mixed').dt.strftime('%m/%d/%Y')\n",
    "adjustments[['ACTUAL','PRIOR']] = adjustments[['ACTUAL','PRIOR']].fillna(0)\n",
    "Res_adj = adjustments[['SHIP_MONTH' ,'SEGMENT' ,'LEGACY_ACCOUNT_NUMBER' ,'ACTUAL', 'PRIOR']]\n",
    "Res_adj = Res_adj.groupby(['SHIP_MONTH' ,'SEGMENT' ,'LEGACY_ACCOUNT_NUMBER']).agg(adjustments_ACTUAL= ('ACTUAL','sum'), adjustments_PRIOR= ('PRIOR', 'sum')).reset_index()\n",
    "\n",
    "    # Merging the df and adj to get the adjusted numbers for ACTUAL and PRIOR\n",
    "Res_adj['SHIP_MONTH'] = pd.to_datetime(Res_adj['SHIP_MONTH'])\n",
    "Res_df['SHIP_MONTH'] = pd.to_datetime(Res_df['SHIP_MONTH'])\n",
    "df_adj = Res_df.merge(Res_adj, how= 'left', on= ['SHIP_MONTH' ,'SEGMENT' ,'LEGACY_ACCOUNT_NUMBER'])\n",
    "\n",
    "df_adj[['adjustments_ACTUAL','adjustments_PRIOR']] = df_adj[['adjustments_ACTUAL','adjustments_PRIOR']].fillna(0)\n",
    "df_adj['ACTUAL'] = (df_adj['%_ACTUAL'] * df_adj['adjustments_ACTUAL']) + df_adj['ACTUAL']\n",
    "df_adj['PRIOR'] = (df_adj['%_PRIOR'] * df_adj['adjustments_PRIOR']) + df_adj['PRIOR']\n",
    "\n",
    "    # Selecting only the important columns\n",
    "data_orders_shipments = df_adj[['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT' , 'LEGACY_ACCOUNT_NUMBER', 'ACTUAL', 'PRIOR']]\n",
    "\n",
    "# Working with demand plan file from demantra\n",
    "# Cleaning the demand_plan dataframe\n",
    "    # Column Renaming\n",
    "data_demand_plan.rename(columns={'Site Cust':'LEGACY_ACCOUNT_NUMBER',\n",
    "                                 'Application Code':'APPLICATION_CODE',\n",
    "                                 'Time':'SHIP_MONTH',\n",
    "                                 'Fiscal Week / Series':'SHIP_WEEK',\n",
    "                                 'DP Plan Proj':'DP_PLAN'\n",
    "                                 }, inplace= True)\n",
    "\n",
    "    # Filter\n",
    "data_dp = data_demand_plan[\n",
    "    (data_demand_plan['SHIP_WEEK'] != 'Summary') & \n",
    "    (data_demand_plan['SHIP_MONTH'] != 'Summary') & \n",
    "    (data_demand_plan['DP_PLAN'] != '0')].copy()\n",
    "\n",
    "    # Changing DP_PLAN value from string to number and removing the week number in SHIP_WEEK.\n",
    "data_dp['DP_PLAN'] = data_dp['DP_PLAN'].apply(lambda x: x.replace(',',''))\n",
    "data_dp['DP_PLAN'] = pd.to_numeric(data_dp['DP_PLAN'])\n",
    "data_dp['SHIP_WEEK'] = data_dp['SHIP_WEEK'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "    # Merging the lookupAPPCODE to get the SEGMENT\n",
    "data_dp = data_dp.merge(lookup_ResAppCode, how='left', left_on= 'APPLICATION_CODE', right_on= 'APP_CODE')\n",
    "\n",
    "    # Making the final demand_plan dataframe to be append in data_orders_shipments.\n",
    "data_dp = data_dp.groupby(['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT' , 'LEGACY_ACCOUNT_NUMBER']).agg(DP_PLAN = ('DP_PLAN','sum')).reset_index()\n",
    "\n",
    "# Combining data_orders_shipments and data_dp\n",
    "data_dp = data_dp.copy()\n",
    "data_orders_shipments = data_orders_shipments.copy()\n",
    "data_dp['SHIP_MONTH'] = pd.to_datetime(data_dp['SHIP_MONTH'])\n",
    "data_dp['SHIP_WEEK'] = pd.to_datetime(data_dp['SHIP_WEEK'], format='%d-%b-%y')\n",
    "data_orders_shipments['SHIP_MONTH'] = pd.to_datetime(data_orders_shipments['SHIP_MONTH'])\n",
    "data_orders_shipments['SHIP_WEEK'] = pd.to_datetime(data_orders_shipments['SHIP_WEEK'])\n",
    "data_complete = pd.concat([data_orders_shipments,data_dp], ignore_index= True)\n",
    "data_complete = data_complete.groupby(['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT' , 'LEGACY_ACCOUNT_NUMBER']).agg(ACTUAL= ('ACTUAL','sum'), PRIOR= ('PRIOR','sum'), DP_PLAN= ('DP_PLAN','sum')).reset_index()\n",
    "\n",
    "# exporting the clean data\n",
    "data_complete.to_csv(folder_path / 'clean_data.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Improvement of code\n",
    "\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(r\"C:\\Users\\E1460340\\Desktop\\New\")\n",
    "\n",
    "# Function to detect encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "# Read datasets\n",
    "dataframes = {}\n",
    "\n",
    "for file in folder_path.iterdir():\n",
    "    if \"Dataset\" in file.name:\n",
    "        for dataset in file.iterdir():\n",
    "            if \"Actual\" in dataset.name:\n",
    "                for actual_file in dataset.iterdir():\n",
    "                    if \"Firm and Forecast Orders\" in actual_file.name:\n",
    "                        dataframes['actual_orders'] = pd.read_csv(actual_file, low_memory=False)\n",
    "                    elif \"Shipment\" in actual_file.name:\n",
    "                        dataframes['actual_shipments'] = pd.read_csv(actual_file, low_memory=False)\n",
    "            \n",
    "            elif \"Prior\" in dataset.name:\n",
    "                for prior_file in dataset.iterdir():\n",
    "                    if \"Firm and Forecast Orders\" in prior_file.name:\n",
    "                        dataframes['prior_orders'] = pd.read_csv(prior_file, low_memory=False)\n",
    "                    elif \"Shipment\" in prior_file.name:\n",
    "                        dataframes['prior_shipments'] = pd.read_csv(prior_file, low_memory=False)\n",
    "\n",
    "            elif \"Demantra\" in dataset.name:\n",
    "                for demantra_file in dataset.iterdir():\n",
    "                    if \"Demantra\" in demantra_file.name:\n",
    "                        encoding = detect_encoding(demantra_file)\n",
    "                        dataframes['demand_plan'] = pd.read_csv(demantra_file, delimiter=\"\\t\", encoding=encoding, low_memory=False)\n",
    "\n",
    "            elif \"factAdjustments\" in dataset.name:\n",
    "                dataframes['adjustments'] = pd.read_excel(dataset, sheet_name=\"Adjustments\")\n",
    "\n",
    "    elif \"Lookup\" in file.name:\n",
    "        for lookup_file in file.iterdir():\n",
    "            excel_file = pd.ExcelFile(lookup_file)\n",
    "            tab_list = excel_file.sheet_names\n",
    "            for tab in tab_list:\n",
    "                dataframes[tab] = pd.read_excel(lookup_file, sheet_name= tab)\n",
    "\n",
    "# Rename columns\n",
    "rename_dict = {\n",
    "    'SCHEDULE_SHIP_DATE': 'SHIP_DATE',\n",
    "    'ORDERED_QUANTITY': 'SHIPPED_QUANTITY',\n",
    "    'Site Cust': 'LEGACY_ACCOUNT_NUMBER',\n",
    "    'Application Code': 'APPLICATION_CODE',\n",
    "    'Time': 'SHIP_MONTH',\n",
    "    'Fiscal Week / Series': 'SHIP_WEEK',\n",
    "    'DP Plan Proj': 'DP_PLAN'\n",
    "}\n",
    "\n",
    "for key in ['actual_orders', 'prior_orders']:\n",
    "    dataframes[key].rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Merge dataframes\n",
    "res_actual = pd.concat([dataframes['actual_shipments'], dataframes['actual_orders']], ignore_index=True)\n",
    "res_prior = pd.concat([dataframes['prior_shipments'], dataframes['prior_orders']], ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "res_actual.rename(columns={'SHIPPED_QUANTITY': 'ACTUAL'}, inplace=True)\n",
    "res_prior.rename(columns={'SHIPPED_QUANTITY': 'PRIOR'}, inplace=True)\n",
    "\n",
    "# Combine datasets\n",
    "res_data = pd.concat([res_actual, res_prior], ignore_index=True)\n",
    "\n",
    "# Apply filtering\n",
    "res_data = res_data[(res_data['CUSTOMER_TYPE'] == 'External') & (res_data['PORBU'] == 'AC_PORBU')]\n",
    "\n",
    "# Merge lookup tables\n",
    "res_data = res_data.merge(dataframes['LOOKUP_RES_PLATFORM'], how='inner', on='PLATFORM')\n",
    "res_data = res_data.merge(dataframes['LOOKUP_RES_APPCODE'], how='left', left_on='APPLICATION_CODE', right_on='APP_CODE').rename(columns={'SEGMENT_y': 'SEGMENT'})\n",
    "\n",
    "# Fill missing SEGMENT valuesL\n",
    "res_data['SEGMENT'] = res_data['SEGMENT'].fillna('OTHERS')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "res_df = res_data[['SHIP_DATE', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER', 'PLATFORM', 'ACTUAL', 'PRIOR']].copy()\n",
    "\n",
    "# Convert SHIP_DATE to datetime and format properly\n",
    "res_df['SHIP_DATE'] = pd.to_datetime(res_df['SHIP_DATE'], format='mixed').dt.strftime(\"%m/%d/%Y\")\n",
    "res_df['SHIP_MONTH'] = pd.to_datetime(res_df['SHIP_DATE']).dt.strftime('%m/1/%Y')\n",
    "res_df['SHIP_WEEK'] = pd.to_datetime(res_df['SHIP_DATE']).dt.to_period('W').dt.start_time.dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "# Group data to reduce row count\n",
    "res_df = res_df.groupby(['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(ACTUAL=('ACTUAL', 'sum'), PRIOR=('PRIOR', 'sum')).reset_index()\n",
    "\n",
    "# Merge adjustments\n",
    "adjustments = dataframes['adjustments'].copy()\n",
    "adjustments['SEGMENT'] = 'RESIDENTIAL'\n",
    "adjustments['SHIP_MONTH'] = pd.to_datetime(adjustments['SHIP_DATE'], format='%d-%b-%y').dt.strftime('%m/%d/%Y')\n",
    "adjustments[['ACTUAL', 'PRIOR']] = adjustments[['ACTUAL', 'PRIOR']].fillna(0)\n",
    "\n",
    "res_adj = adjustments.groupby(['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).agg(adjustments_ACTUAL=('ACTUAL', 'sum'), adjustments_PRIOR=('PRIOR', 'sum')).reset_index()\n",
    "\n",
    "df_adj = res_df.merge(res_adj, how='left', on=['SHIP_MONTH', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER']).fillna(0)\n",
    "df_adj['ACTUAL'] = df_adj['ACTUAL'] + df_adj['adjustments_ACTUAL']\n",
    "df_adj['PRIOR'] = df_adj['PRIOR'] + df_adj['adjustments_PRIOR']\n",
    "\n",
    "# Final dataset\n",
    "data_complete = df_adj[['SHIP_MONTH', 'SHIP_WEEK', 'SEGMENT', 'LEGACY_ACCOUNT_NUMBER', 'ACTUAL', 'PRIOR']]\n",
    "data_complete.to_csv(folder_path / 'clean_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
